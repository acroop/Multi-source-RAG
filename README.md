# ğŸ“„ Multi-Source RAG System (Cloud-Ready)

A **Retrieval-Augmented Generation (RAG)** system that allows users to upload multiple PDF documents, store them in the cloud, and ask natural language questions grounded strictly in the uploaded content.

This project demonstrates **end-to-end RAG architecture**, combining document ingestion, vector embeddings, semantic search, and LLM-based answer generation.

---

## ğŸš€ Key Features

- ğŸ“¤ Upload **multiple PDFs**
- â˜ï¸ PDFs stored in **Supabase Storage (cloud)**
- ğŸ§  Intelligent document parsing using **Unstructured**
- âœ‚ï¸ Title-aware and semantic **chunking**
- ğŸ” Vector-based retrieval using **ChromaDB**
- ğŸ’¬ Natural language Q&A grounded in document context
- ğŸªŸ Clean UI built with **Streamlit**
- ğŸ”Œ Backend powered by **FastAPI**
- ğŸ§© Modular, extensible architecture
- âš™ï¸ Designed for **easy cloud migration**

---

## ğŸ—ï¸ Architecture Overview

Frontend (Streamlit)
â”‚
â–¼
Backend (FastAPI)
â”‚
â”œâ”€â”€ PDF Downloader (from Supabase)
â”œâ”€â”€ Document Parser (Unstructured)
â”œâ”€â”€ Chunking Logic
â”œâ”€â”€ Embedding Generator
â”œâ”€â”€ Vector Store (ChromaDB)
â””â”€â”€ Answer Generator (LLM)

Cloud Services:

Supabase Storage â†’ PDFs

> **Note:**  
> During development, embeddings are stored locally using ChromaDB.  
> The system is designed so the vector database can be migrated to a **cloud-hosted vector store** (Chroma Server / pgvector) without changing core RAG logic.

---

## ğŸ§  Tech Stack

### Frontend
- **Streamlit** â€“ interactive UI

### Backend
- **FastAPI** â€“ REST API
- **Uvicorn** â€“ ASGI server

### Document Processing
- **Unstructured** â€“ PDF partitioning
- **Poppler + Tesseract** (for hi-res parsing)

### Embeddings & Retrieval
- **ChromaDB**
- **HuggingFace Embeddings**
  - `sentence-transformers/all-MiniLM-L6-v2`

### Cloud
- **Supabase Storage** â€“ PDF storage
- **Environment Variables** â€“ secrets management


---

## ğŸ”„ Data Flow

### 1ï¸âƒ£ PDF Upload
- User uploads PDFs via Streamlit
- Files are uploaded to **Supabase Storage**
- Public (or signed) URLs are generated

### 2ï¸âƒ£ Ingestion Pipeline
- Backend downloads PDFs from Supabase
- Documents are partitioned using Unstructured
- Content is chunked intelligently
- Embeddings are generated
- Vectors are stored in ChromaDB

### 3ï¸âƒ£ Question Answering
- User asks a question
- Relevant chunks retrieved via vector similarity
- Context passed to LLM
- Grounded answer generated and returned

---

## ğŸ§ª Example API Endpoints

### ğŸ“¥ Ingest Documents
POST /ingest

**Payload**
```json
{
  "filename": "attention-is-all-you-need.pdf",
  "pdf_url": "<supabase_url>"
}
```

Ask a Question
POST /ask

**Payload**

```json
{
  "question": "What is self-attention?",
}
```

## ğŸ› ï¸ Setup Instructions
1ï¸âƒ£ Clone Repository

```
git clone <repo-url>
cd Multi-Source-RAG
```

2ï¸âƒ£ Create Virtual Environment

```
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate
```

3ï¸âƒ£ Install Dependencies

```
pip install -r backend/requirements.txt
```

4ï¸âƒ£ Environment Variables

Create .env:
```
SUPABASE_URL=your_supabase_url
SUPABASE_ANON_KEY=your_key
```

5ï¸âƒ£ Run Backend
```
cd backend
uvicorn main:app --reload
```

6ï¸âƒ£ Run Frontend
```
cd frontend
streamlit run app.py
```


## ğŸ”® Future Enhancements

- â˜ï¸ Cloud-hosted vector DB (Chroma Server / pgvector)
- ğŸ“‘ Multi-document filtering & global search
- ğŸ§  Conversation memory
- ğŸ” Authentication & user isolation
- âš¡ Streaming LLM responses
- ğŸ“Š Evaluation & confidence scoring
- ğŸ³ Dockerized deployment
- ğŸ”„ CI/CD pipeline

## ğŸ‘¨â€ğŸ’» Author
**Supratik Das**

Engineering Student | Full Stack | AI & RAG Systems


### â­ Acknowledgements
- LangChain
- HuggingFace
- Supabase
- Unstructured
- ChromaDB

>If you find this project useful, feel free to â­ the repo!
